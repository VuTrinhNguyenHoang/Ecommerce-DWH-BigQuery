{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy category id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36 Edg/128.0.0.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'vi,en;q=0.9,en-US;q=0.8',\n",
    "    'Referer': 'https://tiki.vn/dien-thoai-may-tinh-bang/c1789',\n",
    "    'x-guest-token': 'f1kXJZDbVQ8N0PFzH3E92yKUeg4Wa6wY',\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'limit': '40',\n",
    "    'include': 'advertisement',\n",
    "    'aggregations': '2',\n",
    "    'trackity_id': '563cc097-0278-3210-d9eb-2b08ef7b99a0',\n",
    "    'category': '1789',\n",
    "    'page': '1',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_id = []\n",
    "repo = requests.get(\"https://tiki.vn/\", headers=headers, params=params)\n",
    "soup = BeautifulSoup(repo.text, 'html.parser')\n",
    "\n",
    "soup = soup.find('div', class_='styles__StyledListItem-sc-w7gnxl-0 cjqkgR')\n",
    "a = soup.find_all('a')\n",
    "for i in a:\n",
    "    match = re.search(r'/c(\\d+)', i['href'])\n",
    "    categories_id.append(match.group(1))\n",
    "\n",
    "categories_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy id của sản phẩm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = []\n",
    "for j in categories_id:\n",
    "    params['category'] = j\n",
    "    for i in range(1, 2):\n",
    "        params['page'] = i\n",
    "        response = requests.get('https://tiki.vn/api/personalish/v1/blocks/listings', headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            # print(\"requests complete\")\n",
    "            for record in response.json().get('data'):\n",
    "                product_id.append({'id': record.get('id')})\n",
    "print(len(product_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(product_id)\n",
    "df = set(df['id'])\n",
    "df = pd.DataFrame(df)\n",
    "df.rename(columns={0: 'id'}, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy comment trên từng sản phẩm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36 Edg/134.0.0.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'vi,en;q=0.9,en-US;q=0.8',\n",
    "    'Referer': 'https://tiki.vn/ke-toan-via-he-thuc-hanh-bao-cao-tai-chinh-can-ban-tu-quay-ban-nuoc-chanh-p262977989.html?',\n",
    "    'x-guest-token': 'pUYHub5GIMswKcLtmv6gzl9yDFo8Cd7E',\n",
    "    'Connection': 'keep-alive',\n",
    "    'TE': 'Trailers',\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'product_id': '',\n",
    "    'sort': 'score|desc,id|desc,stars|all',\n",
    "    'page': '1',\n",
    "    'limit': '10',\n",
    "    'include': 'comments'\n",
    "}\n",
    "\n",
    "def comment_parser(json):\n",
    "    d = dict()\n",
    "    d['id'] = json.get(id)\n",
    "    d['title'] = json.get('title')\n",
    "    d['content'] = json.get('content')\n",
    "    d['thank_count'] = json.get('thank_count')\n",
    "    d['customer_id']  = json.get('customer_id')\n",
    "    d['rating'] = json.get('rating')\n",
    "    d['created_at'] = json.get('created_at')\n",
    "    d['customer_name'] = json.get('created_by').get('full_name')\n",
    "    d['purchased_at'] = json.get('created_by').get('purchased_at')\n",
    "    return d\n",
    "\n",
    "p_ids = df.id.to_list()[:10]\n",
    "result = []\n",
    "for pid in tqdm(p_ids, total=len(p_ids)):\n",
    "    params['product_id'] = pid\n",
    "    print('Crawl comment for product {}'.format(pid))\n",
    "    for i in range(1):\n",
    "        params['page'] = i\n",
    "        yes = 1\n",
    "        while(yes):\n",
    "            try:\n",
    "                response = requests.get('https://tiki.vn/api/v2/reviews?', headers=headers, params=params)\n",
    "                if response.status_code == 200:\n",
    "                    for comment in response.json().get('data'):\n",
    "                        result.append(comment_parser(comment))\n",
    "                    print('Crawl comment page {} success!!!'.format(i))\n",
    "                yes = 0\n",
    "            except:\n",
    "                print('Crawl data {} fail !!!'.format(pid))\n",
    "        \n",
    "df_comment = pd.DataFrame(result)\n",
    "df_comment.to_csv('comments_data_ncds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://tiki.vn/api/v2/reviews?', headers=headers, params=params)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy thông tin sản phẩm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'vi-VN,vi;q=0.8,en-US;q=0.5,en;q=0.3',\n",
    "    'Referer': 'https://tiki.vn/dien-thoai-samsung-galaxy-m31-128gb-6gb-hang-chinh-hang-p58259141.html?src=category-page-1789&2hi=0',\n",
    "    'x-guest-token': '8jWSuIDBb2NGVzr6hsUZXpkP1FRin7lY',\n",
    "    'Connection': 'keep-alive',\n",
    "    'TE': 'Trailers',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('platform', 'web'),\n",
    "    ('spid', 187266106)\n",
    ")\n",
    "\n",
    "def parser_product(json):\n",
    "    d = dict()\n",
    "    d['id'] = json.get('id')\n",
    "    d['sku'] = json.get('sku')\n",
    "    d['short_description'] = json.get('short_description')\n",
    "    d['price'] = json.get('price')\n",
    "    d['list_price'] = json.get('list_price')\n",
    "    d['discount'] = json.get('discount')\n",
    "    d['discount_rate'] = json.get('discount_rate')\n",
    "    d['review_count'] = json.get('review_count')\n",
    "    d['all_time_quantity_sold'] = json.get('all_time_quantity_sold')\n",
    "    d['inventory_status'] = json.get('inventory_status')\n",
    "    d['stock_item_qty'] = json.get('stock_item').get('qty')\n",
    "    d['stock_item_max_sale_qty'] = json.get('stock_item').get('max_sale_qty')\n",
    "    d['product_name'] = json.get('name')\n",
    "    d['brand_id'] = json.get('brand').get('id')\n",
    "    d['brand_name'] = json.get('brand').get('name')\n",
    "    return d\n",
    "\n",
    "p_ids = df.id.to_list()\n",
    "print(p_ids)\n",
    "result = []\n",
    "for pid in tqdm(p_ids, total=len(p_ids)):\n",
    "    print(pid)\n",
    "    yes = 1\n",
    "    while(yes):\n",
    "        try:\n",
    "            response = requests.get('https://tiki.vn/api/v2/products/{}'.format(pid), headers=headers, params=params)\n",
    "            print('Crawl data {} success !!!'.format(pid))\n",
    "            result.append(parser_product(response.json()))\n",
    "            yes = 0\n",
    "        except:\n",
    "            print('Crawl data {} fail !!!'.format(pid))\n",
    "        \n",
    "df_product = pd.DataFrame(result)\n",
    "df_product.to_csv('crawled_data_ncds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Tạo SparkSession với cấu hình kết nối đến HDFS trên container thông qua localhost\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Write to HDFS\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o240.parquet.\n: org.apache.hadoop.ipc.RpcException: RPC response has invalid length\r\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1933)\r\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)\r\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhdfs://localhost:9000/user/airflow/comments/mydata.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Ghi DataFrame vào HDFS ở định dạng Parquet\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile đã được ghi vào HDFS tại:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_path)\n\u001b[0;32m     14\u001b[0m spark\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[1;32mc:\\Users\\ha200\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:1721\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[1;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[1;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ha200\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ha200\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\ha200\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o240.parquet.\n: org.apache.hadoop.ipc.RpcException: RPC response has invalid length\r\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1933)\r\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)\r\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)\r\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ tạo DataFrame\n",
    "data = [(\"Alice\", 25), (\"Bob\", 30)]\n",
    "columns = [\"name\", \"age\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Đường dẫn trên HDFS (đảm bảo đường dẫn và cổng đã được map trong docker-compose)\n",
    "output_path = \"hdfs://localhost:9000/user/airflow/comments/mydata.parquet\"\n",
    "\n",
    "# Ghi DataFrame vào HDFS ở định dạng Parquet\n",
    "df.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "print(\"File đã được ghi vào HDFS tại:\", output_path)\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"List HDFS Folders\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://172.18.0.6:9000\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc file Parquet\n",
    "try:\n",
    "    df = spark.read.parquet(\"hdfs://172.18.0.6:9000/user/airflow/comments/comment_inmemory_20250311_145408.parquet\")\n",
    "    df.show()\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi: {e}\")\n",
    "\n",
    "# Đóng SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Tạo SparkSession với cấu hình HDFS\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"List HDFS Folders\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Lấy đối tượng FileSystem từ Hadoop configuration\n",
    "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "\n",
    "# Đường dẫn gốc trên HDFS\n",
    "path = spark._jvm.org.apache.hadoop.fs.Path(\"hdfs://localhost:9000/user/airflow/comments\")\n",
    "\n",
    "# Liệt kê các file và thư mục trong đường dẫn\n",
    "file_status = fs.listStatus(path)\n",
    "\n",
    "\n",
    "print(\"Các folder trên HDFS:\")\n",
    "for status in file_status:\n",
    "    print(status.getPath().toString())\n",
    "\n",
    "# Dừng SparkSession khi xong\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
